{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECTION OF DISPLASTIC FEATURES IN ORAL HISTOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVICE SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"images\"  # Update with actual path\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/val\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Normal', 'OSCC']\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "num_classes = len(train_dataset.classes)  # Should be 2 (Normal, OSCC)\n",
    "print(\"Classes:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/15], Loss: 0.6535, LR: 0.010000\n",
      "Epoch [2/15], Loss: 0.6136, LR: 0.010000\n",
      "Epoch [3/15], Loss: 0.5842, LR: 0.010000\n",
      "Epoch [4/15], Loss: 0.5695, LR: 0.010000\n",
      "Epoch [5/15], Loss: 0.5339, LR: 0.005000\n",
      "Epoch [6/15], Loss: 0.4926, LR: 0.005000\n",
      "Epoch [7/15], Loss: 0.4483, LR: 0.005000\n",
      "Epoch [8/15], Loss: 0.4200, LR: 0.005000\n",
      "Epoch [9/15], Loss: 0.4055, LR: 0.005000\n",
      "Epoch [10/15], Loss: 0.3748, LR: 0.002500\n",
      "Epoch [11/15], Loss: 0.3476, LR: 0.002500\n",
      "Epoch [12/15], Loss: 0.3225, LR: 0.002500\n",
      "Epoch [13/15], Loss: 0.3223, LR: 0.002500\n",
      "Epoch [14/15], Loss: 0.3083, LR: 0.002500\n",
      "Epoch [15/15], Loss: 0.2935, LR: 0.001250\n",
      "Training Complete!\n",
      "Model Saved!\n",
      "\n",
      "Validation Set Performance:\n",
      "Accuracy: 0.8000, Precision: 0.9048, Recall: 0.8261, F1-score: 0.8636\n",
      "Confusion Matrix:\n",
      "[[20  8]\n",
      " [16 76]]\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.8730, Precision: 0.9341, Recall: 0.8947, F1-score: 0.9140\n",
      "Confusion Matrix:\n",
      "[[25  6]\n",
      " [10 85]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.873015873015873,\n",
       " 0.9340659340659341,\n",
       " 0.8947368421052632,\n",
       " 0.9139784946236559,\n",
       " array([[25,  6],\n",
       "        [10, 85]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.01  # Adjusted for SGD\n",
    "num_epochs = 15\n",
    "weight_decay = 1e-4  # L2 Regularization\n",
    "dropout_rate = 0.3  # Dropout to prevent overfitting\n",
    "\n",
    "# Data Augmentation & Normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Dataset path\n",
    "data_dir = \"images\"\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/val\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=transform)\n",
    "\n",
    "# Compute class weights for imbalanced dataset\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# CNN Model with Dropout\n",
    "class OralHistologyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OralHistologyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, optimizer, and scheduler\n",
    "model = OralHistologyCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)  # Weighted loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)  # SGD + Momentum\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Reduce LR after 5 epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()  # Adjust learning rate\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "# Save model correctly\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_weights': class_weights,\n",
    "    'hyperparameters': {\n",
    "        'learning_rate': learning_rate,\n",
    "        'num_epochs': num_epochs,\n",
    "        'dropout_rate': dropout_rate\n",
    "    }\n",
    "}, \"oral_histology_cnn.pth\")\n",
    "print(\"Model Saved!\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, dataloader, dataset_name):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device).long()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(f\"\\n{dataset_name} Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    return accuracy, precision, recall, f1, cm\n",
    "\n",
    "# Load model for evaluation\n",
    "checkpoint = torch.load(\"oral_histology_cnn.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on Validation and Test Set\n",
    "evaluate_model(model, val_loader, \"Validation\")\n",
    "evaluate_model(model, test_loader, \"Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
